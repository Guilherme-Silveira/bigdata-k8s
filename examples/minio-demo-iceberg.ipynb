{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "conf = SparkConf()\n",
    " \n",
    "conf.setMaster(\"k8s://https://kubernetes.default:443\")\n",
    "\n",
    "conf.setAppName(\"Spark minIO Test\")\n",
    "conf.set(\"spark.hadoop.fs.s3a.endpoint\", \"http://minio-minio-storage:9000\")\n",
    "conf.set(\"spark.hadoop.fs.s3a.access.key\", \"silveira\")\n",
    "conf.set(\"spark.hadoop.fs.s3a.secret.key\", \"guilherme@123\")\n",
    "conf.set(\"spark.hadoop.fs.s3a.path.style.access\", True)\n",
    "conf.set(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "conf.set('spark.hadoop.fs.s3a.aws.credentials.provider', 'org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider')\n",
    "conf.set(\"spark.kubernetes.container.image\", \"guisilveira/spark-base\") \n",
    "conf.set(\"spark.kubernetes.container.image.pullPolicy\", \"Always\")\n",
    "conf.set(\"spark.kubernetes.authenticate.caCertFile\", \"/run/secrets/kubernetes.io/serviceaccount/ca.crt\")\n",
    "conf.set(\"spark.kubernetes.authenticate.oauthTokenFile\", \"/run/secrets/kubernetes.io/serviceaccount/token\")\n",
    "conf.set(\"spark.kubernetes.namespace\", \"bigdata\")\n",
    "conf.set(\"spark.kubernetes.authenticate.driver.serviceAccountName\", \"jupyterhub\")\n",
    "conf.set(\"spark.executor.instances\", \"2\")\n",
    "conf.set(\"spark.executor.memory\", \"2g\")\n",
    "conf.set(\"spark.executorEnv.AWS_REGION\", os.getenv('AWS_REGION'))\n",
    "conf.set(\"spark.executorEnv.AWS_ACCESS_KEY_ID\", os.getenv('AWS_ACCESS_KEY_ID'))\n",
    "conf.set(\"spark.executorEnv.AWS_SECRET_ACCESS_KEY\", os.getenv('AWS_SECRET_ACCESS_KEY'))\n",
    "conf.set(\"spark.driver.bindAddress\", \"0.0.0.0\")\n",
    "conf.set(\"spark.driver.host\", \"jupyterhub\") \n",
    "conf.set(\"spark.driver.port\", 7078)\n",
    "conf.set(\"spark.driver.blockManager.port\", 7079)\n",
    "conf.set(\"hive.metastore.uris\", \"thrift://hive:9083\")\n",
    "conf.set(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\")\n",
    "conf.set(\"spark.sql.catalog.spark_catalog\", \"org.apache.iceberg.spark.SparkSessionCatalog\")\n",
    "conf.set(\"spark.sql.catalog.spark_catalog.type\", \"hive\")\n",
    "conf.set(\"spark.sql.catalog.spark_catalog.uri\", \"thrift://hive:9083\")\n",
    "conf.set(\"spark.sql.catalog.spark_catalog.io-impl\", \"org.apache.iceberg.aws.s3.S3FileIO\")\n",
    "conf.set(\"spark.sql.catalog.spark_catalog.warehouse\", \"s3://warehouse/iceberg\")\n",
    "conf.set(\"spark.sql.catalog.spark_catalog.s3.endpoint\", \"http://minio-minio-storage:9000\")\n",
    "conf.set(\"spark.sql.warehouse.dir\", \"s3a://warehouse/iceberg\")\n",
    "conf.set(\"iceberg.engine.hive.enabled\", \"true\")\n",
    "conf.set(\"spark.sql.defaultCatalog\", \"spark_catalog\")\n",
    "\n",
    "spark = SparkSession.builder.config(conf=conf).enableHiveSupport().getOrCreate()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
